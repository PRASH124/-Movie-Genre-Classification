{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FoxeNnbK6d79"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Read dataset files\n",
        "def read_txt_file(filepath):\n",
        "    with open(filepath, 'r', encoding='utf-8') as file:\n",
        "        return file.readlines()\n",
        "\n",
        "# Load data\n",
        "train_data = read_txt_file('/mnt/data/train_data.txt')\n",
        "test_data = read_txt_file('/mnt/data/test_data.txt')\n",
        "test_labels = read_txt_file('/mnt/data/test_data_solution.txt')\n",
        "\n",
        "def parse_data(data):\n",
        "    plots = []\n",
        "    genres = []\n",
        "    for line in data:\n",
        "        parts = line.strip().split('\\t')  # Adjust delimiter if needed\n",
        "        if len(parts) > 1:\n",
        "            plots.append(parts[0])\n",
        "            genres.append(parts[1].split('|'))  # Assuming multi-label genres\n",
        "    return plots, genres\n",
        "\n",
        "# Parse train and test data\n",
        "train_plots, train_genres = parse_data(train_data)\n",
        "test_plots, test_genres = parse_data(test_labels)  # Actual labels\n",
        "\n",
        "# Convert genres to binary labels\n",
        "all_genres = set([genre for sublist in train_genres for genre in sublist])\n",
        "train_labels = pd.DataFrame([[1 if genre in genres else 0 for genre in all_genres] for genres in train_genres], columns=all_genres)\n",
        "test_labels = pd.DataFrame([[1 if genre in genres else 0 for genre in all_genres] for genres in test_genres], columns=all_genres)\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# Apply preprocessing\n",
        "train_plots = [preprocess_text(plot) for plot in train_plots]\n",
        "test_plots = [preprocess_text(plot) for plot in test_plots]\n",
        "\n",
        "# TF-IDF vectorization\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = vectorizer.fit_transform(train_plots)\n",
        "X_test_tfidf = vectorizer.transform(test_plots)\n",
        "\n",
        "# Train model\n",
        "model = OneVsRestClassifier(LogisticRegression())\n",
        "model.fit(X_train_tfidf, train_labels)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluation\n",
        "print(classification_report(test_labels, y_pred, target_names=list(all_genres)))"
      ]
    }
  ]
}